{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. RL girdworld.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKVqfK0j20_n"
      },
      "source": [
        "import sys\n",
        "from io import StringIO\n",
        "from gym.envs.toy_text import discrete\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from random import choice\n",
        "import random\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxTk5RUT3C_O",
        "outputId": "05a98b88-5912-45ba-dca0-14be1eaeee58"
      },
      "source": [
        "NORTH = 0\n",
        "EAST = 1\n",
        "SOUTH = 2\n",
        "WEST = 3\n",
        "\n",
        "class Gridworld(discrete.DiscreteEnv): \n",
        "  metadata = {'render.modes': ['human', 'ansi']}\n",
        "  def __init__(self, shape=[9, 9]):\n",
        "    self.shape = shape\n",
        "  \n",
        "    nS = np.prod(shape)\n",
        "    nA = 4\n",
        "\n",
        "    MAX_Y = shape[0]\n",
        "    MAX_X = shape[1]\n",
        "\n",
        "    P = {}\n",
        "    grid = np.arange(nS).reshape(shape)\n",
        "    it = np.nditer(grid, flags=['multi_index'])\n",
        "\n",
        "    while not it.finished:\n",
        "        s = it.iterindex\n",
        "        y, x = it.multi_index\n",
        "\n",
        "        P[s] = {a: [] for a in range(nA)}\n",
        "\n",
        "        # Build wall \n",
        "        self.wall = []\n",
        "        self.block1 = np.array([3, 4, 5, 6, 7])\n",
        "        self.block2 = np.array([2, 3, 4, 5])\n",
        "        self.block3 = np.array([3, 4, 5, 6])\n",
        "        self.build_wall()\n",
        "\n",
        "        # Define snakepit and treasure \n",
        "        self.snakepit = self.shape[0] * 6 + 5  \n",
        "        self.treasure = self.shape[0] * 8 + 8  \n",
        "\n",
        "        if s == self.snakepit:reward = -50.0\n",
        "        elif s == self.treasure: reward = 50.0\n",
        "        else: reward = -1.0\n",
        "\n",
        "        if s == self.snakepit:\n",
        "            P[s][NORTH] = [(1.0, s, reward, True)]\n",
        "            P[s][EAST] = [(1.0, s, reward, True)]\n",
        "            P[s][SOUTH] = [(1.0, s, reward, True)]\n",
        "            P[s][WEST] = [(1.0, s, reward, True)]\n",
        "        else:   \n",
        "            # Moving North \n",
        "            if y == 0 or (y == 2 and x in [2, 3, 4, 5, 6]) or (y == 8 and x in [1, 2, 3, 4]) or (y == 6 and x == 6):\n",
        "                move_north = s\n",
        "            else:\n",
        "                move_north = s - MAX_X\n",
        "            # Moving East \n",
        "            if x == (MAX_X - 1) or (y == 1 and x == 1) or (y == 7 and x == 0) or (x == 5 and y in [2, 3, 4, 5]):\n",
        "                move_east = s\n",
        "            else:\n",
        "                move_east = s + 1\n",
        "            # Moving South \n",
        "            if y == (MAX_Y - 1) or (y == 0 and x in [2, 3, 4, 5, 6]) or (y == 6 and x in [1, 2, 3, 4]):\n",
        "                move_south = s\n",
        "            else:\n",
        "                move_south = s + MAX_X\n",
        "            # Moving West\n",
        "            if x == 0 or (y == 7 and x == 5) or (x == 7 and y in [1, 2, 3, 4, 5]):\n",
        "                move_west = s\n",
        "            else:\n",
        "                move_west = s - 1\n",
        "\n",
        "            P[s][NORTH] = [(1.0, move_north, reward, self.is_terminal(move_north))]\n",
        "            P[s][EAST] = [(1.0, move_east, reward, self.is_terminal(move_east))]\n",
        "            P[s][SOUTH] = [(1.0, move_south, reward, self.is_terminal(move_south))]\n",
        "            P[s][WEST] = [(1.0, move_west, reward, self.is_terminal(move_west))]\n",
        "\n",
        "        it.iternext()\n",
        "\n",
        "    isd = np.ones(nS) / nS\n",
        "\n",
        "    # Near by states \n",
        "    P[self.snakepit + 9][NORTH] = [(1.0, self.snakepit, -50.0, True)]\n",
        "    P[self.snakepit - 1][EAST] = [(1.0, self.snakepit, -50.0, True)]\n",
        "    P[self.snakepit - 9][SOUTH] = [(1.0, self.snakepit, -50.0, True)]\n",
        "    P[self.snakepit + 1][WEST] = [(1.0, self.snakepit, -50.0, True)]\n",
        "    P[self.treasure - 1][EAST] = [(1.0, self.treasure, 50.0, True)]\n",
        "    P[self.treasure - 9][SOUTH] = [(1.0, self.treasure, 50.0, True)]\n",
        "    self.P = P\n",
        "\n",
        "    super(Gridworld, self).__init__(nS, nA, P, isd)\n",
        "\n",
        "  def build_wall(self):\n",
        "    for block in self.block1:\n",
        "        self.wall.append(self.shape[0] * (2 - 1) + block - 1)\n",
        "    for block in self.block2:\n",
        "        self.wall.append(self.shape[0] * (8 - 1) + block - 1)   \n",
        "    for block in self.block3:\n",
        "        self.wall.append(self.shape[0] * (block - 1) + 7 - 1)\n",
        "  \n",
        "\n",
        "  def is_terminal(self, s):\n",
        "      return True if s == self.snakepit or s == self.treasure else False\n",
        "\n",
        "  def _render(self, mode='human', close=False):\n",
        "      if close:\n",
        "          return\n",
        "\n",
        "      outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
        "\n",
        "      grid = np.arange(self.nS).reshape(self.shape)\n",
        "      it = np.nditer(grid, flags=['multi_index'])\n",
        "      while not it.finished:\n",
        "          s = it.iterindex\n",
        "          y, x = it.multi_index\n",
        "\n",
        "          if self.s == s:\n",
        "              output = \" X \" \n",
        "          elif self.is_terminal(s):\n",
        "              output = \" \" + chr(9443) + ' '\n",
        "          elif s in self.wall:\n",
        "              output = \" \" + chr(9618) + ' '\n",
        "          else:\n",
        "              output = \" . \"\n",
        "\n",
        "          if x == 0:\n",
        "              output = output.lstrip()\n",
        "          if x == self.shape[1] - 1:\n",
        "              output = output.rstrip()\n",
        "\n",
        "          outfile.write(output)\n",
        "\n",
        "          if x == self.shape[1] - 1:\n",
        "              outfile.write(\"\\n\")\n",
        "\n",
        "          it.iternext()\n",
        "      print(\"\\n\")\n",
        "\n",
        "env = Gridworld((9, 9))\n",
        "env._render(mode=\"human\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".  .  .  .  .  .  .  .  .\n",
            ".  .  ▒  ▒  ▒  ▒  ▒  .  .\n",
            ".  .  .  .  .  .  ▒  .  .\n",
            ".  .  .  .  .  .  ▒  .  .\n",
            ".  .  .  .  .  .  ▒  .  .\n",
            ".  .  .  .  .  .  ▒  .  .\n",
            ".  .  X  .  .  ⓣ  .  .  .\n",
            ".  ▒  ▒  ▒  ▒  .  .  .  .\n",
            ".  .  .  .  .  .  .  .  ⓣ\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNxFDNMx8lw-"
      },
      "source": [
        "## Monte carlo evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb4Z6VEn3GAi"
      },
      "source": [
        "def generate_random_episode(env):\n",
        "    episode = []\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "    episode.append((state, -1))\n",
        "    while not done:\n",
        "        action = choice(list(env.P[state].keys())) \n",
        "        next_state = env.P[state][action][0][1]\n",
        "        reward = env.P[state][action][0][2]\n",
        "        done = env.P[state][action][0][3]\n",
        "        episode.append((next_state, reward))\n",
        "        if next_state == 0:\n",
        "            done = True\n",
        "        state = next_state\n",
        "    return episode"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBp38lq08oZa"
      },
      "source": [
        "def monte_carlo(env, num_iter):\n",
        "    values = np.zeros(env.observation_space.n) \n",
        "    returns = dict()\n",
        "    for state in range(env.observation_space.n):\n",
        "        returns[state] = list()\n",
        "    \n",
        "    for i in range(num_iter):\n",
        "        episode = generate_random_episode(env)\n",
        "        already_visited = set({0})  \n",
        "        for s, r in episode:\n",
        "            if s not in already_visited:\n",
        "                already_visited.add(s)\n",
        "                idx = episode.index((s, r))\n",
        "                G = 0\n",
        "                j = 1\n",
        "                while j + idx < len(episode):\n",
        "                    G = gamma * (G + episode[j + idx][1])\n",
        "                    j += 1\n",
        "                returns[s].append(G)\n",
        "                values[s] = np.mean(returns[s])\n",
        "    return values, returns\n",
        "gamma = 1.0\n",
        "values, returns = monte_carlo(env, 500)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "rbkMXSZw8r42",
        "outputId": "17e62ee6-dbbe-4696-ed4d-e82d66c55ac7"
      },
      "source": [
        "def show_values(values):\n",
        "    values = values.reshape(env.shape)\n",
        "    ax = seaborn.heatmap(values, cmap = \"Blues_r\", annot = False, linecolor=\"#282828\", linewidths = 0.1)\n",
        "    plt.show()\n",
        "show_values(values)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF0pI3r7Hu6q"
      },
      "source": [
        "## SARSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ibhf4exDGXx"
      },
      "source": [
        "def SARSA(env, discount, step_size, num_episodes):  \n",
        "    states = env.P \n",
        "    actions = [0,1,2,3]\n",
        "    values = defaultdict(dict)\n",
        "\n",
        "    # creating random inital policy \n",
        "    for state in states:\n",
        "        for action in actions:\n",
        "            values[state][action] = random.uniform(0,1)\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        init_state = choice(list(set(env.P.keys())))\n",
        "        init_action = max(values[init_state].items(), key=lambda a: a[1])[0] \n",
        "        \n",
        "        while not env.is_terminal(init_state):\n",
        "            reward = env.P[init_state][init_action][0][2]\n",
        "            next_state = env.P[init_state][init_action][0][1]\n",
        "            next_action = max(values[next_state].items(), key=lambda a: a[1])[0] \n",
        "            \n",
        "            values[init_state][init_action] += step_size * (reward + discount * values[next_state][next_action]\n",
        "                                                       - values[init_state][init_action])\n",
        "            init_state = next_state\n",
        "            init_action = next_action\n",
        "        sys.stdout.flush()\n",
        "    return values\n",
        "\n",
        "sarsa_val = SARSA(env, 1.0, 0.9, 50000)    "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0uCnoxGMNOd",
        "outputId": "68aa9ada-b4b0-475a-ce01-438a74c23f4c"
      },
      "source": [
        "def show_selected_actions(values): \n",
        "  count = 0 \n",
        "  for j in range(9):\n",
        "    layer = []\n",
        "    for i in range(j,j+9):\n",
        "      layer.append(max(values[count].items(), key=lambda a: a[1])[0])\n",
        "      count +=1\n",
        "    print(layer)\n",
        "\n",
        "show_selected_actions(sarsa_val)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 2, 2]\n",
            "[2, 2, 1, 0, 1, 0, 1, 2, 2]\n",
            "[2, 2, 2, 2, 2, 3, 1, 1, 2]\n",
            "[2, 2, 3, 2, 3, 3, 1, 2, 3]\n",
            "[2, 2, 3, 3, 2, 2, 1, 2, 2]\n",
            "[1, 2, 3, 3, 2, 3, 2, 1, 2]\n",
            "[2, 3, 3, 3, 3, 3, 2, 2, 2]\n",
            "[2, 0, 0, 0, 1, 2, 1, 2, 2]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjjtP1EqX4Jr"
      },
      "source": [
        "## q learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWTDZ-2iUzom"
      },
      "source": [
        "def q_learning(env, discount, step_size, num_episodes):\n",
        "    states = env.P \n",
        "    actions = [0,1,2,3]\n",
        "    values = defaultdict(dict)\n",
        "\n",
        "    # creating random inital policy \n",
        "    for state in states:\n",
        "        for action in actions:\n",
        "            values[state][action] = random.uniform(0,1)\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        init_state = choice(list(set(env.P.keys())))  \n",
        "        while not env.is_terminal(init_state):\n",
        "            init_action = max(values[init_state].items(), key=lambda a: a[1])[0]  \n",
        "            reward = env.P[init_state][init_action][0][2]\n",
        "            next_state = env.P[init_state][init_action][0][1]\n",
        "\n",
        "            best_val = max(values[next_state].items(), key=lambda a: a[1])[1]\n",
        "            values[init_state][init_action] += step_size * (reward + discount * best_val\n",
        "                                                       - values[init_state][init_action])\n",
        "            init_state = next_state\n",
        "        sys.stdout.flush()\n",
        "    return values\n",
        "\n",
        "q_vals = q_learning(env, 1.0, 0.9, 50000)    \n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EW4s3zNYkyM",
        "outputId": "2697145f-ed3a-437d-d277-9cb85b1dbde6"
      },
      "source": [
        "show_selected_actions(q_vals)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 2, 2]\n",
            "[1, 0, 0, 0, 0, 0, 3, 2, 2]\n",
            "[2, 2, 2, 3, 2, 3, 1, 2, 2]\n",
            "[2, 2, 2, 3, 2, 2, 1, 2, 2]\n",
            "[2, 3, 3, 3, 3, 3, 1, 1, 2]\n",
            "[2, 2, 3, 3, 2, 3, 1, 2, 2]\n",
            "[2, 3, 3, 3, 3, 2, 1, 2, 2]\n",
            "[2, 3, 0, 0, 2, 1, 1, 2, 2]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuGQNf3aY4rh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}